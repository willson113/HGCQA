## To comprehensively and rigorously evaluate LLM performance on HGCQA while minimizing experimental variance, we selected seven distinct LLM categories varying in parameter scale and architecture, sourced from Baidu AI Cloud Platform and Zhipu AI's API deployments.

## Llama-7B/Llama2-13B/Llama2-70B

![baidu](https://github.com/user-attachments/assets/2962caa5-a98b-407c-a791-8eacecc0a887)

## ChatGLM2-6B
![1744728393975](https://github.com/user-attachments/assets/fe95177c-bbc2-482d-ad21-589b9feac7d4)

## ERNIE-3.5
![1744728437749](https://github.com/user-attachments/assets/33deb99a-996d-4818-b3fc-1c412558a0e9)

## GLM3-Turbo GLM-4
![1744728611714](https://github.com/user-attachments/assets/ca3b286c-91b7-4bde-945d-e5921f851e5b)
