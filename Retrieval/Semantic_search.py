import os
import json
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.schema import Document
from langchain.llms import BaiduWenxin

# â€”â€”â€” 0. è®¾ç½® API Key â€”â€”â€”
os.environ["BAIDU_API_KEY"] = "your_apikey"  # æ›¿æ¢ä¸ºä½ çš„æ–‡å¿ƒAPI key

# â€”â€”â€” 1. åŠ è½½é—®é¢˜æ•°æ®é›† HGCQA â€”â€”â€”
with open("HGCQA.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# â€”â€”â€” 2. åŠ è½½æœ¬åœ° bge-m3 æ¨¡å‹ â€”â€”â€”
embeddings = HuggingFaceEmbeddings(model_name="/data/bge-m3")

# â€”â€”â€” 3. åŠ è½½ Chroma å‘é‡åº“ï¼ˆæŒä¹…åŒ–è·¯å¾„ï¼‰ â€”â€”â€”
vectordb = Chroma(
    persist_directory="/data/Chroma_db",  # å‘é‡åº“ç›®å½•
    embedding_function=embeddings
)

# â€”â€”â€” 4. åˆ›å»º MMR æ£€ç´¢å™¨ï¼ˆæå‡å¤šæ ·æ€§ï¼‰ â€”â€”â€”
retriever = vectordb.as_retriever(
    search_type="mmr",
    search_kwargs={
        "k": 6,             # è¿”å›å‰6ä¸ªæ®µè½
        "lambda_mult": 0.7  # æ§åˆ¶ç›¸å…³æ€§å’Œå¤šæ ·æ€§çš„æƒé‡
    }
)

# â€”â€”â€” 5. åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆæ–‡å¿ƒä¸€è¨€ï¼‰ â€”â€”â€”
llm = BaiduWenxin(model="ernie-bot-turbo", api_key="your_apikey")
tools = "ChromaRetriever"

# â€”â€”â€” 6. å¤šè½®æ¨ç†æç¤ºæ¨¡æ¿ï¼ˆReAct é£æ ¼ï¼‰ â€”â€”â€”
prompt_template = """è¯·ä½ å°½é‡ç®€æ˜æ‰¼è¦åœ°å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œå¹¶æ ¹æ®éœ€è¦ä½¿ç”¨ä»¥ä¸‹å·¥å…·:{tools}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”:
é—®é¢˜: ä½ éœ€è¦å›ç­”çš„é—®é¢˜
æ€è€ƒ: ä½ åº”è¯¥é¦–å…ˆè€ƒè™‘å¦‚ä½•å¤„ç†é—®é¢˜
è¡ŒåŠ¨: ä½ éœ€è¦é‡‡å–çš„è¡ŒåŠ¨ï¼Œåº”è¯¥æ˜¯[{tools}]
è¡ŒåŠ¨è¾“å…¥: è¡ŒåŠ¨æ‰€éœ€çš„è¾“å…¥
è§‚å¯Ÿ: è¡ŒåŠ¨çš„ç»“æœ
â€¦(è¿™ä¸ªæ€è€ƒ/è¡ŒåŠ¨/è¡ŒåŠ¨è¾“å…¥/è§‚å¯Ÿè¿‡ç¨‹å¯ä»¥é‡å¤é›¶æ¬¡æˆ–å¤šæ¬¡)

### ç‰¹åˆ«è¯´æ˜:
1. å¦‚æœä½ åœ¨ç¬¬3è½®æ—¶ä»æ— æ³•ç¡®å®šç­”æ¡ˆï¼Œè¯·ä½¿ç”¨åæ€ç­–ç•¥ï¼Œå¯¹å·²è·å–çš„ä¿¡æ¯è¿›è¡Œåæ€ï¼Œä»¥æ£€éªŒæ˜¯å¦é—æ¼äº†ä»»ä½•å…³é”®ä¿¡æ¯æˆ–é€»è¾‘é”™è¯¯ã€‚
2. å¦‚æœä½ åœ¨ç¬¬6è½®ä»æ— æ³•ç¡®å®šç­”æ¡ˆï¼Œæ— è®ºæ˜¯å¦å®Œå…¨ç¡®å®šï¼Œè¯·ç»™å‡ºä½ æ¨æ–­å‡ºçš„æœ€ç»ˆç­”æ¡ˆã€‚ä½ å¯ä»¥æ˜ç¡®è¯´æ˜ç­”æ¡ˆçš„ä¸ç¡®å®šæ€§ã€‚
3. å¦‚æœä½ ç¡®å®šå¯ä»¥ç›´æ¥å›ç­”é—®é¢˜ï¼Œè¯·ç«‹å³ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼Œé¿å…ä¸å¿…è¦çš„å·¥å…·è°ƒç”¨ã€‚
4. åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œå°½é‡å‡å°‘è¿­ä»£æ¬¡æ•°ï¼Œå¹¶é€šè¿‡æ£€ç´¢è¡¥å……å¿…è¦ä¿¡æ¯ã€‚

### å¼€å§‹!
é—®é¢˜:{imnput}
æ€è€ƒ:{fagent_scratchpad}
"""

# â€”â€”â€” 7. æ–­ç‚¹ç»­è·‘æœºåˆ¶ â€”â€”â€”
output_path = "answer.json"
if os.path.exists(output_path):
    with open(output_path, "r", encoding="utf-8") as f:
        results = json.load(f)
    start_idx = len(results)
    print(f"ğŸ” æ£€æµ‹åˆ°å·²æœ‰ {start_idx} æ¡ç»“æœï¼Œå°†ä»ç¬¬ {start_idx+1} æ¡ç»§ç»­å¤„ç†ã€‚")
else:
    results = []
    start_idx = 0

# â€”â€”â€” 8. ä¸»å¾ªç¯ï¼šè¯­ä¹‰æ£€ç´¢ + å¤šè½®æ€è€ƒ + å®æ—¶å†™å…¥ â€”â€”â€”
for idx in range(start_idx, len(data)):
    item = data[idx]
    q = item["question"]
    qtype = item["type"]

    try:
        # 8.1 ä½¿ç”¨ MMR æ£€ç´¢ç›¸å…³æ®µè½ï¼ˆTop 6ï¼‰
        docs = retriever.get_relevant_documents(q)
        context = "\n\n".join([doc.page_content for doc in docs])

        # 8.2 æ‹¼æ¥ Prompt è¾“å…¥
        prompt = (
            f"æ®µè½ï¼š\n{context}\n\n" +
            prompt_template.format(
                tools=tools,
                imnput=q,
                fagent_scratchpad=""
            )
        )

        # 8.3 è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ
        pred = llm(prompt).strip()

    except Exception as e:
        pred = f"Error: {e}"

    # 8.4 ä¿å­˜ç»“æœ
    results.append({
        "question": q,
        "answer": pred,
        "type": qtype
    })
    print(f"[{idx+1}/{len(data)}] Q: {q}\nA: {pred}\nType: {qtype}\n")

    # 8.5 å®æ—¶å†™å…¥ answer.jsonï¼ˆé¿å…å´©æºƒä¸¢å¤±ï¼‰
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

print("âœ… æ‰€æœ‰é—®é¢˜å¤„ç†å®Œæ¯•ï¼Œç­”æ¡ˆå·²å†™å…¥ answer.json")
